APP="/factory/workers/extractors/youtube_transcriber_v3/youtube_transcriber.py"

sudo tee "$APP" >/dev/null <<'PY'
import os
import re
import time
import json
import uuid
import random
import logging
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import (
    TranscriptsDisabled,
    NoTranscriptFound,
    # TooManyRequests may not exist in older versions; don't import it
)

# -------- Config --------
LOG_DIR = os.environ.get("YT_LOG_DIR", "/factory/logs")
DATA_DIR = os.environ.get("YT_DATA_DIR", "/factory/data/raw/youtube_transcripts")
VIDEOS_FILE = os.environ.get("YT_VIDEOS_FILE", "/etc/youtube_transcriber/videos.txt")

MAX_WORKERS = int(os.environ.get("YT_MAX_WORKERS", "4"))
PER_FETCH_SLEEP_MIN = float(os.environ.get("YT_PER_FETCH_SLEEP_MIN", "0.7"))
PER_FETCH_SLEEP_MAX = float(os.environ.get("YT_PER_FETCH_SLEEP_MAX", "1.5"))
CYCLE_SAMPLE = int(os.environ.get("YT_CYCLE_SAMPLE", "6"))
REST_PERIOD_SECONDS = int(os.environ.get("YT_REST_SECONDS", str(5*60)))
LANG_PREFS = os.environ.get("YT_LANG_PREFS", "es,en").split(",")
RETRIES = int(os.environ.get("YT_RETRIES", "3"))
BACKOFF_BASE = float(os.environ.get("YT_BACKOFF_BASE", "1.8"))
# ------------------------

Path(LOG_DIR).mkdir(parents=True, exist_ok=True)
Path(DATA_DIR).mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    filename=str(Path(LOG_DIR) / "youtube_transcriber_v3.log"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logging.getLogger().addHandler(logging.StreamHandler())

ID_RE = re.compile(r"^[A-Za-z0-9_-]{11}$")

def load_video_ids(path: str) -> list[str]:
    p = Path(path)
    if not p.exists():
        logging.warning(f"Videos file not found at {path}; creating a starter file.")
        starter = [
            "5__3_kN2z8g","8_4-sW9_a2Q","k_nSg4Q62kU","HAn91k2-b_I","h_1-8aEj2-w",
            "_d45-66q_Q","rWp5s4O2mB8","P1ww1IX4i1Q","_X-y_3-g_iM","XdddbYILack",
            "zhL5DCizj5c","M2QfJp_1iA4","k-K8_204_lA","vo4pMVb0R6M","wxa02-294F4",
            "vfe-eNq-Qyg","E43-CfukEgs","5pXxoyk5wOo","bBC-nXj3Ng4","1aRj-1g_V-w",
        ]
        p.parent.mkdir(parents=True, exist_ok=True)
        p.write_text("\n".join(starter) + "\n", encoding="utf-8")

    vids = []
    for line in p.read_text(encoding="utf-8").splitlines():
        s = line.strip()
        if not s or s.startswith("#"): continue
        if ID_RE.match(s): vids.append(s)
        else: logging.warning(f"Skipping invalid YouTube ID: {s}")
    vids = list(dict.fromkeys(vids))
    random.shuffle(vids)
    return vids

def choose_transcript(video_id: str):
    """
    Prefer manual transcripts in LANG_PREFS order, then generated, then any.
    Avoids poking private attributes that may change across versions.
    """
    transcripts = YouTubeTranscriptApi.list_transcripts(video_id)

    # Try manual by preference
    for lang in LANG_PREFS:
        try:
            t = transcripts.find_manually_created_transcript([lang])
            return (t.language_code, t.fetch())
        except Exception:
            pass

    # Try generated by preference
    for lang in LANG_PREFS:
        try:
            t = transcripts.find_generated_transcript([lang])
            return (t.language_code, t.fetch())
        except Exception:
            pass

    # Fallback: take the first available transcript
    for t in transcripts:
        try:
            return (t.language_code, t.fetch())
        except Exception:
            continue

    # If we reached here, nothing worked
    raise NoTranscriptFound(video_id)

def save_outputs(video_id: str, language: str, items: list[dict]):
    out_dir = Path(DATA_DIR) / video_id
    out_dir.mkdir(parents=True, exist_ok=True)

    text = " ".join(chunk.get("text", "").replace("\n", " ").strip() for chunk in items).strip()
    (out_dir / f"{video_id}.txt").write_text(text, encoding="utf-8")

    meta = {
        "video_id": video_id,
        "language": language,
        "chunks": items,
        "characters": len(text),
        "saved_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "run_id": str(uuid.uuid4()),
    }
    (out_dir / f"{video_id}.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")

def looks_rate_limited(err: Exception) -> bool:
    s = str(err).lower()
    return ("429" in s) or ("rate" in s and "limit" in s) or ("too many request" in s) or ("quota" in s)

def fetch_with_retry(video_id: str):
    delay = 1.0
    for attempt in range(1, RETRIES + 1):
        try:
            logging.info(f"[{video_id}] Attempt {attempt}/{RETRIES}")
            lang, items = choose_transcript(video_id)
            save_outputs(video_id, lang, items)
            logging.info(f"[{video_id}] OK (lang={lang}, segments={len(items)})")
            return True
        except (TranscriptsDisabled, NoTranscriptFound) as e:
            logging.warning(f"[{video_id}] No transcript available: {e}")
            return False
        except Exception as e:
            if looks_rate_limited(e):
                logging.warning(f"[{video_id}] Rate limited or quota issue: {e} - backing off {delay:.1f}s")
            else:
                logging.warning(f"[{video_id}] Error: {e} - backing off {delay:.1f}s")
        time.sleep(delay)
        delay *= BACKOFF_BASE
    logging.error(f"[{video_id}] Failed after {RETRIES} attempts.")
    return False

def main():
    logging.info("=== YouTube Transcriber v3 starting ===")
    while True:
        all_ids = load_video_ids(VIDEOS_FILE)
        if not all_ids:
            logging.warning("No valid IDs found. Sleeping...")
            time.sleep(30)
            continue

        batch = all_ids[:CYCLE_SAMPLE] if len(all_ids) >= CYCLE_SAMPLE else all_ids
        logging.info(f"Selected {len(batch)} video(s) this cycle.")

        results = []
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:
            futures = {}
            for vid in batch:
                time.sleep(random.uniform(0.1, 0.4))  # jitter to reduce burstiness
                futures[pool.submit(fetch_with_retry, vid)] = vid

            for fut in as_completed(futures):
                vid = futures[fut]
                ok = False
                try:
                    ok = fut.result()
                except Exception as e:
                    logging.error(f"[{vid}] Unexpected worker error: {e}")
                results.append((vid, ok))
                time.sleep(random.uniform(PER_FETCH_SLEEP_MIN, PER_FETCH_SLEEP_MAX))

        ok_count = sum(1 for _, ok in results if ok)
        logging.info(f"Cycle done. {ok_count}/{len(results)} succeeded. Sleeping {REST_PERIOD_SECONDS}s...")
        time.sleep(REST_PERIOD_SECONDS)

if __name__ == "__main__":
    main()
PY

sudo systemctl daemon-reload
sudo systemctl restart youtube_transcriber_v3.service
